{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# N-Gram Generator for Sisense",
      "metadata": {
        "tags": [],
        "cell_id": "00000-4a9e87d4-7bb3-4560-85d1-7ba9e4445fce",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Setup\n\nMake sure that the language you will be running this script on is supported by a matching SpaCy pretrained model: https://spacy.io/usage/models",
      "metadata": {
        "tags": [],
        "cell_id": "00001-b9f40173-8009-43e3-bb62-1f10973cf7f3",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": null,
        "execution_millis": 19896,
        "execution_start": 1616076250030,
        "cell_id": "00000-ef2d1d69-47b6-42b9-930c-a1605df504c3",
        "is_output_hidden": false,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\nimport numpy as np\nimport re\n\nimport nltk, re, string, collections\nfrom nltk.util import ngrams # function for making ngrams\n\nfrom collections import Counter\nfrom collections import defaultdict \n\nfrom matplotlib.pyplot import plot\n\nimport spacy\n\n!python3 -m spacy download fr_core_news_sm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Load the data into the ```df``` variable.\nIf using Sisense Custom Code, point the query output to this variable.",
      "metadata": {
        "tags": [],
        "cell_id": "00003-a27dfe9c-1846-421e-a89d-76adc0f17014",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": null,
        "execution_millis": 9,
        "execution_start": 1616076453615,
        "cell_id": "00001-df2c9ef7-e7be-4129-a946-a04659aeebcd",
        "is_output_hidden": false,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "df = pd.read_csv('customer_data.csv')\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Load the SpaCy model for the language of your choice\n#### The cell below is formatted for french.\n\nFor English you would use ```nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])```\n\nWe disable the **parser** and **ner** components of the SpaCy pipeline for speed. We are not using them in this application.",
      "metadata": {
        "tags": [],
        "cell_id": "00005-e1fcfb42-4c72-4b8e-b4b5-50ecba838759",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ebb2ce14",
        "execution_millis": 1058,
        "execution_start": 1616076459255,
        "cell_id": "00002-21d35e0a-d931-47c8-8fa6-8a52dc5fd3c3",
        "deepnote_cell_type": "code"
      },
      "source": "nlp = spacy.load('fr_core_news_sm', disable=['parser', 'ner'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### This function will return the tokens for ngram generation\nAdd additional logic to customize what tokens are produced for ngram generation.",
      "metadata": {
        "tags": [],
        "cell_id": "00007-3882441e-3587-4996-a569-81e62c7746c0",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "95fd09c6",
        "execution_millis": 7,
        "execution_start": 1616076397872,
        "cell_id": "00003-e9247699-8abe-4788-aea2-2d0eca62c901",
        "deepnote_cell_type": "code"
      },
      "source": "def clean(document):\n    return [token.lemma_ for token in nlp(document) if (token.is_stop == False and token.pos_ == 'NOUN' and token.lemma_ != 'oui')]",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Settings\n\n##### ```ngram_depth:``` how many words should be comined in the ngram.\n>1: \"product\"\n\n>2: \"product is\"\n\n>3: \"product is great\"\n\n##### ```limit:``` For each ngram above the order of 1, ```limit``` is the number of children ngrams that must exist for the higher order ngram to be added to the list.\nThis logic cuts down on the amount of processing that is needed for higher order ngrams.\n\n##### ```min_ngram_length:``` Prune ngrams that are below this order. Default is 1 or no pruning.\n##### ```one_gram_frequency:``` Prune 1-grams that show up less than this amount of times. Default is 10.\n\n##### ```text_column:``` The column containing text to analyze\n##### ```id_column:``` The ID column that will join the output to the full text",
      "metadata": {
        "tags": [],
        "cell_id": "00009-d8763cab-92f8-487e-88e1-2f3525c0f37b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-b7898f1d-570b-4951-b329-9ffc4d9ffaf2",
        "deepnote_cell_type": "code"
      },
      "source": "ngram_depth = 3\nlimit = 3\nmin_ngram_length = 1\none_gram_frequency_min = 10\n\ntext_column = 'CustomerText'\nid_column = 'CallId'",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Execute ngram object generation",
      "metadata": {
        "tags": [],
        "cell_id": "00011-36bfd3c4-aa68-45c5-8b19-8a826a65fd8e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "60a1d3d0",
        "execution_millis": 1061801,
        "execution_start": 1615947438661,
        "cell_id": "00004-16d726c8-54e4-45a6-aa79-847ca4d56e52",
        "deepnote_cell_type": "code"
      },
      "source": "counter = Counter()\nmapping = defaultdict(set)\n\nfor ngram_order in range(1,ngram_depth+1):\n    for index, row in df.iterrows(): \n        index = row[id_column]\n        tokens = clean(row[text_column])\n    \n        if len(tokens) >= ngram_order:\n            ngram_set = ngrams(tokens, ngram_order)\n            if ngram_order == 1:\n                for ngram in ngram_set:\n                    counter[ngram] += 1\n                    mapping[ngram].add(index)\n            else:\n                for ngram in ngram_set:\n                    front_parent = counter.get(ngram[1:], 0)\n                    back_parent = counter.get(ngram[:-1], 0)\n                    if front_parent >= limit or back_parent >= limit:\n                        counter[ngram] += 1\n                        mapping[ngram].add(index)\n        \nif min_ngram_length != 1:\n    for key in [key for key in counter if len(key) < min_ngram_length]: \n        del counter[key]\n            \nif one_gram_frequency_min != 1:\n    for key in [key for key in counter if counter[key] < one_gram_frequency_min and len(key) == 1]: \n        del counter[key]",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Create dataframes for joining tables and expoding related text IDs into columns",
      "metadata": {
        "tags": [],
        "cell_id": "00013-e62c2353-953d-478d-a8c0-8bb0aebec8b8",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": null,
        "execution_millis": 537,
        "execution_start": 1615948500499,
        "cell_id": "00005-3feb4c4e-084b-4f3b-9bcd-afaf626f2ac9",
        "is_output_hidden": false,
        "output_cleared": true,
        "deepnote_cell_type": "code"
      },
      "source": "counts_df = pd.DataFrame({'keys':counter.keys()})\nprint('counts df', counts_df.head())\n\nmapping_df = pd.DataFrame({'keys':mapping.keys(), 'indexes':mapping.values()})\nprint('mapping df before explode', mapping_df.head())\n\nmapping_df = mapping_df.explode('indexes')\nprint('mapping df after explode', mapping_df.head())\n\noutput_df = pd.merge(counts_df, mapping_df, how='inner', on='keys')\n\n# review final output\nprint('\\nhead\\n')\nprint(output_df.head())\nprint('\\ntail\\n')\nprint(output_df.tail())",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Clean final output and add ngram length for dashboard filtering",
      "metadata": {
        "tags": [],
        "cell_id": "00015-106f91b1-3bf2-48b0-90e1-6086c8eddb9e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b6b29b61",
        "execution_millis": 44530,
        "execution_start": 1615948504814,
        "cell_id": "00008-b8a64810-5f4f-42bf-b599-a25cc3f61574",
        "deepnote_cell_type": "code"
      },
      "source": "output_df = output_df[output_df['keys'] != ('nan',)]\noutput_df['ngram_length'] = output_df.apply(lambda row: len(row['keys']), axis=1)\noutput_df['keys'] = output_df.apply(lambda row: ' '.join(row['keys']), axis=1)\n\nprint(output_df.head())\nprint(output_df.tail())",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Out to CSV\nIf this is in Sisense Custom Code, this last cell is not necessary",
      "metadata": {
        "tags": [],
        "cell_id": "00017-6db8f5de-284b-474a-9d3c-0164dffb0c65",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": null,
        "execution_millis": 145,
        "cell_id": "00009-e1f282bc-f31e-4e8b-aaab-729f551b5dc6",
        "output_cleared": true,
        "execution_start": 1616110542458,
        "deepnote_cell_type": "code"
      },
      "source": "output_df.to_csv('ngrams_no_oui.csv', index=False)",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f9bad575-1d72-4d96-91fe-cd9123bf1420' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "b33ccb79-e796-440b-9937-ddabfcf64446",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}